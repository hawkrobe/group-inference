{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(30000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 30 seconds\n"
     ]
    }
   ],
   "source": [
    "##### import packages\n",
    "#base\n",
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%autosave 30\n",
    "\n",
    "#pyro contingency\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro import poutine\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, TraceEnum_ELBO, config_enumerate, infer_discrete, Predictive\n",
    "from pyro.ops.indexing import Vindex\n",
    "from pyro.infer import MCMC, NUTS\n",
    "import torch\n",
    "from torch.distributions import constraints\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "#misc\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import time\n",
    "# import umap\n",
    "# import plotly\n",
    "# import plotly.graph_objs as go\n",
    "\n",
    "# import homebrew modules\n",
    "import tomtom_models as tm\n",
    "import tomtom_util as tu\n",
    "\n",
    "# some useless warnings from seaborn, suppressing here\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "# global tself_norm_all_3d, tself_norm_noauto_3d, tself_raw_all_3d, tself_raw_noauto_3d\n",
    "# global ttarg_norm_all_3d, ttarg_norm_noauto_3d, ttarg_raw_all_3d, ttarg_raw_noauto_3d\n",
    "# global tavg_norm_all_3d, tavg_norm_noauto_3d, tavg_raw_all_3d, tavg_raw_noauto_3d\n",
    "\n",
    "# import pickled data\n",
    "with open('tomtom_data_preprocessed.pkl','rb') as f:\n",
    "    [tself_norm_all_3d, tself_norm_noauto_3d, tself_raw_all_3d, tself_raw_noauto_3d,\n",
    "    ttarg_norm_all_3d, ttarg_norm_noauto_3d, ttarg_raw_all_3d, ttarg_raw_noauto_3d,\n",
    "    tavg_norm_all_3d, tavg_norm_noauto_3d, tavg_raw_all_3d, tavg_raw_noauto_3d] = pickle.load(f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search through feature-value combinations\n",
    "\n",
    "1. One vs. Three transitions (all triplet combinations)\n",
    "2. 0.1-0.9 on each feature\n",
    "3. group model - classify + sample to get the likelihood of each cluster\n",
    "4. dimension model - learn individual mixture weight of each component, currently incomplete\n",
    "\n",
    "All done using modeling/scripts-cluster/stimuli-generation, but code included here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running SVI with: tself_raw_noauto_3d\n",
      "seed = 63, initial_loss = 16388.033203125\n",
      "..............................\n",
      " final loss: -1032.6170654296875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set model fitting params\n",
    "tm.K = 3\n",
    "tm.mtype = 'group'\n",
    "tm.target = 'self' # 'self','targ','avg'\n",
    "tm.dtype = 'raw' # 'norm','raw'\n",
    "tm.auto = 'noauto' # 'noauto','all'\n",
    "tm.stickbreak = False\n",
    "tm.optim = pyro.optim.Adam({'lr': 0.0005, 'betas': [0.8, 0.99]})\n",
    "tm.elbo = TraceEnum_ELBO(max_plate_nesting=1)\n",
    "dtname = 't{}_{}_{}_3d'.format(tm.target, tm.dtype, tm.auto)\n",
    "data = globals()[dtname]\n",
    "seed_grp, mapl_grp, mem_grp, lp_grp, guide_grp = tm.tomtom_svi(data,return_guide = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining sparse-input model\n",
    "@config_enumerate\n",
    "def model_multi_obs_grp(obsmat):\n",
    "    # some parameters can be directly derived from the data passed\n",
    "    # K = 2\n",
    "    nparticipants = data.shape[0]\n",
    "    nfeatures = data.shape[1] # number of rows in each person's matrix\n",
    "    ncol = data.shape[2]\n",
    "    \n",
    "    # Background probability of different groups\n",
    "    if tm.stickbreak:\n",
    "        # stick breaking process for assigning weights to groups\n",
    "        with pyro.plate(\"beta_plate\", K-1):\n",
    "            beta_mix = pyro.sample(\"weights\", dist.Beta(1, 10))\n",
    "        weights = tm.mix_weights(beta_mix)\n",
    "    else:\n",
    "        weights = pyro.sample('weights', dist.Dirichlet(0.5 * torch.ones(tm.K)))\n",
    "    # declare model parameters based on whether the data are row-normalized\n",
    "    if tm.dtype == 'norm':\n",
    "        pass\n",
    "#         with pyro.plate('components', K):\n",
    "#             # concentration parameters\n",
    "#             concentration = pyro.sample('concentration',\n",
    "#                                         dist.Gamma(2 * torch.ones(nfeatures,ncol), 1/3 * torch.ones(nfeatures,ncol)).to_event(2))\n",
    "        \n",
    "#         # implementation for the dirichlet based model is not complete!!!!\n",
    "#         with pyro.plat('data',obsmat.shape[0]):\n",
    "#             assignment = pyro.sample('assignment', dist.Categorical(weights))\n",
    "#             #d = dist.Dirichlet(concentration[assignment,:,:].clone().detach()) # .detach() might interfere with backprop\n",
    "#             d = dist.Dirichlet(concentration[assignment,i,:])\n",
    "#             pyro.sample('obs', d.to_event(1), obs=obsmat)\n",
    "\n",
    "    elif tm.dtype == 'raw':\n",
    "        with pyro.plate('components', tm.K):\n",
    "            alphas = pyro.sample('alpha', dist.Gamma(2 * torch.ones(nfeatures,ncol), 1/3 * torch.ones(nfeatures,ncol)).to_event(2))\n",
    "            betas = pyro.sample('beta', dist.Gamma(2 * torch.ones(nfeatures,ncol), 1/3 * torch.ones(nfeatures,ncol)).to_event(2))\n",
    "\n",
    "        assignment = pyro.sample('assignment', dist.Categorical(weights))\n",
    "        # expand assignment to make dimensions match\n",
    "        for r in np.arange(obsmat.shape[0]):\n",
    "            rowind = obsmat[r,1].type(torch.long)\n",
    "            colind = obsmat[r,2].type(torch.long)\n",
    "            d = dist.Beta(alphas[assignment,rowind,colind],betas[assignment,rowind,colind])\n",
    "            pyro.sample('obs_{}'.format(r), d, obs = obsmat[r,0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_obs classifier\n",
    "guide_trace = poutine.trace(guide_grp).get_trace(data)  # record the globals\n",
    "trained_model_multi = poutine.replay(model_multi_obs_grp, trace = guide_trace)\n",
    "\n",
    "def classifier_multi_obs(obsmat, temperature): # temperature = 1 to sample\n",
    "    inferred_model = infer_discrete(trained_model_multi, temperature=temperature,\n",
    "                                    first_available_dim=-1)  # avoid conflict with data plate\n",
    "    trace = poutine.trace(inferred_model).get_trace(obsmat)\n",
    "    return trace.nodes[\"assignment\"][\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Feature\n",
    "# initialize storage\n",
    "niter = 500\n",
    "nsteps = np.arange(.1,1,.1).shape[0]\n",
    "stor_grp = torch.empty(size = [data.shape[1],data.shape[2],nsteps])\n",
    "stor_grp_prb = torch.empty(size = [data.shape[1],data.shape[2],nsteps,tm.K])\n",
    "# iterate through all features, each with value .1-.9\n",
    "for row in np.arange(data.shape[1]):\n",
    "    for col in np.arange(data.shape[2]):\n",
    "        step_count = 0\n",
    "        for step in np.arange(.1,1,.1):\n",
    "            newdata = torch.tensor([step, row, col]).unsqueeze(0)\n",
    "            # first MAP classification\n",
    "            grp = classifier_multi_obs(newdata, temperature = 0)\n",
    "            stor_grp[row,col,step_count] = grp\n",
    "            # second use sampling to get group prob\n",
    "            stor = torch.zeros(niter)\n",
    "            for it in np.arange(niter):\n",
    "                stor[it] = classifier_multi_obs(newdata, temperature = 1)\n",
    "            grp_prb = [(stor == i).sum()/float(len(stor)) for i in np.arange(tm.K)]\n",
    "            stor_grp_prb[row,col,step_count,:] = torch.tensor(grp_prb)\n",
    "            step_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Three Features\n",
    "# dfr = pd.DataFrame({'row':np.arange(data.shape[1]),'key': 1})\n",
    "# dfc = pd.DataFrame({'col':np.arange(data.shape[2]),'key': 1})\n",
    "# coord =pd.merge(dfr,dfc,on='key').drop('key',1) # mapping each cell to their row/col index, just another way to do cartesian product but indexing later is easier\n",
    "# cellcombo = list(itertools.combinations(np.arange(60),3))\n",
    "# nstim = 3\n",
    "# stepcombo = list(itertools.product(np.arange(.1,1,.1), repeat = nstim))\n",
    "# allsteps = np.arange(.1,1,.1)\n",
    "# nsteps = allsteps.shape[0]\n",
    "# # stor_grp_3feat = torch.empty(size = [len(cellcombo),nsteps,nsteps,nsteps])\n",
    "# # stor_grp_prb_3feat = torch.empty(size = [len(cellcombo),nsteps,nsteps,nsteps,K])\n",
    "\n",
    "# def combo_3feat(comb):\n",
    "#     comb_counter = cellcombo.index(comb)\n",
    "#     #first identify all row and col indices\n",
    "#     rs = coord.loc[np.array(comb),'row']\n",
    "#     cs = coord.loc[np.array(comb),'col']\n",
    "#     # print(comb_counter)\n",
    "#     stor = torch.empty(size = [nsteps, nsteps, nsteps])\n",
    "#     stor_prb = torch.empty(size = [nsteps, nsteps, nsteps, K])\n",
    "#     for step in stepcombo:\n",
    "#         newdata = torch.tensor(np.stack((step,rs,cs),1))\n",
    "#         step1 = np.where(allsteps == step[0])[0][0] # can try to make this generalize for arbitrary nstim, seems hard tho\n",
    "#         step2 = np.where(allsteps == step[1])[0][0]\n",
    "#         step3 = np.where(allsteps == step[2])[0][0]\n",
    "#         # first MAP classification\n",
    "#         grp = classifier_multi_obs(newdata, temperature = 0)\n",
    "#         stor[step1,step2,step3] = grp\n",
    "#         #second use sampling to get group prob\n",
    "#         s = torch.zeros(niter)\n",
    "#         for it in np.arange(niter):\n",
    "#             s[it] = classifier_multi_obs(newdata, temperature = 1)\n",
    "#         grp_prb = [(s == i).sum()/float(len(s)) for i in np.arange(K)]\n",
    "#         stor_prb[step1,step2,step3,:] = torch.tensor(grp_prb)\n",
    "#     print('Finished combo {}'.format(comb_counter))\n",
    "#     return stor, stor_prb\n",
    "\n",
    "# import multiprocessing\n",
    "\n",
    "# ta = time.time()\n",
    "# pool = multiprocessing.Pool()\n",
    "# pool_out = pool.map(combo_3feat, cellcombo[0:20])\n",
    "# stor_grp_3feat = torch.stack([tt[0] for tt in pool_out])\n",
    "# stor_grp_prb_3feat = torch.stack([tt[1] for tt in pool_out])\n",
    "# print(time.time() - ta)\n",
    "# print(stor_grp_3feat.shape)\n",
    "# print(stor_grp_prb_3feat.shape)\n",
    "# print(stor_grp_prb_3feat[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model fitting params\n",
    "tm.K = 3\n",
    "tm.mtype = 'dim'\n",
    "tm.target = 'self' # 'self','targ','avg'\n",
    "tm.dtype = 'raw' # 'norm','raw'\n",
    "tm.auto = 'noauto' # 'noauto','all'\n",
    "tm.stickbreak = False\n",
    "tm.optim = pyro.optim.Adam({'lr': 0.0005, 'betas': [0.8, 0.99]})\n",
    "tm.elbo = TraceEnum_ELBO(max_plate_nesting=1)\n",
    "\n",
    "dtname = 't{}_{}_{}_3d'.format(tm.target, tm.dtype, tm.auto)\n",
    "data = globals()[dtname]\n",
    "seed_dim, mapl_dim, lp_dim, guide_dim = tm.tomtom_svi(data,return_guide = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running SVI with: tself_raw_noauto_3d\n",
      "seed = 37, initial_loss = 16926.279296875\n",
      "..............................\n",
      " final loss: -1246.4873046875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model fitting\n",
    "pyro.clear_param_store()\n",
    "#declare dataset to be modeled\n",
    "dtname = 't{}_{}_{}_3d'.format(target, dtype, auto)\n",
    "print(\"running SVI with: {}\".format(dtname))\n",
    "# data = globals()[dtname]\n",
    "data = vars()[dtname]\n",
    "\n",
    "loss, seed = min((initialize(seed,model,data), seed) for seed in range(100))\n",
    "initialize(seed,model,data)\n",
    "print('seed = {}, initial_loss = {}'.format(seed, loss))\n",
    "\n",
    "# gradient_norms = defaultdict(list)\n",
    "# for name, value in pyro.get_param_store().named_parameters():\n",
    "#     value.register_hook(lambda g, name=name: gradient_norms[name].append(g.norm().item()))\n",
    "\n",
    "losses = []\n",
    "for i in range(3000):\n",
    "    loss = svi.step(data)\n",
    "    #print(loss)\n",
    "    losses.append(loss)\n",
    "    if i % 100 == 0:\n",
    "        print('.',end = '')\n",
    "#             print(loss)\n",
    "print('\\n final loss: {}\\n'.format(losses[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic_weights': tensor([0.5256, 0.4224, 0.7553], grad_fn=<ExpandBackward>),\n",
       " 'topic_a': tensor([[[ 3.8767,  2.2639,  1.7345,  2.4200],\n",
       "          [ 1.8958,  1.7205,  6.2372,  1.8286],\n",
       "          [ 1.5057,  2.8178,  1.7273,  1.2591],\n",
       "          [ 1.1103,  3.4179,  1.1312,  0.9376],\n",
       "          [ 3.1478,  1.3969,  1.4844,  3.3614],\n",
       "          [ 1.3401,  2.2661,  7.9908,  7.9658],\n",
       "          [ 1.4839,  1.0624,  1.9212,  1.1917],\n",
       "          [ 1.4579,  1.6259, 10.5371, 14.1060],\n",
       "          [ 2.5557,  1.8333,  2.0099,  1.9113],\n",
       "          [ 1.4944,  1.1536,  7.7213,  3.7645],\n",
       "          [ 1.3890,  1.2069,  2.8325,  1.5430],\n",
       "          [ 1.6162,  1.4605,  3.4062,  2.4597],\n",
       "          [ 1.0064,  1.4142,  1.9132,  1.9076],\n",
       "          [ 5.1878,  1.5064,  1.0376,  1.5434],\n",
       "          [ 3.8488,  1.3164,  1.7821,  1.5674]],\n",
       " \n",
       "         [[ 6.7035,  2.5486,  2.2294,  2.5348],\n",
       "          [ 1.6712,  1.4842,  8.0454,  3.2342],\n",
       "          [ 1.4314,  3.5516,  1.8442,  2.2266],\n",
       "          [ 0.9618,  5.6168,  1.9249,  1.6595],\n",
       "          [ 3.8400,  1.1135,  1.7267,  3.3971],\n",
       "          [ 1.6798,  4.7496,  5.3113, 11.0885],\n",
       "          [ 3.9508,  1.4773,  2.2704,  0.8403],\n",
       "          [ 1.7692,  1.8643,  5.6281,  9.4084],\n",
       "          [ 6.0973,  1.5754,  1.2324,  1.5367],\n",
       "          [ 1.9569,  2.6110,  4.1487,  5.5807],\n",
       "          [ 2.3254,  2.4427,  2.6034,  2.3508],\n",
       "          [ 2.4683,  1.7490,  4.5877,  2.6805],\n",
       "          [ 1.7263,  1.2393,  1.9439,  6.5121],\n",
       "          [ 5.2125,  1.5597,  1.3521,  3.1533],\n",
       "          [ 3.3141,  2.0629,  2.0025,  2.5821]],\n",
       " \n",
       "         [[ 6.9315,  1.0479,  1.0568,  1.7772],\n",
       "          [ 0.8919,  1.0156,  6.9070,  2.4269],\n",
       "          [ 0.9207,  1.7856,  1.0666,  1.4467],\n",
       "          [ 1.0861,  1.0413,  1.1251,  1.3995],\n",
       "          [ 2.3389,  1.7337,  0.9859,  2.2008],\n",
       "          [ 1.4906,  1.0676,  6.0461,  4.4557],\n",
       "          [ 1.2217,  0.8643,  1.2761,  1.7665],\n",
       "          [ 1.0324,  1.2068,  6.1488,  9.3974],\n",
       "          [ 1.4232,  0.9971,  0.7453,  1.8846],\n",
       "          [ 1.7314,  1.4745,  5.4033,  1.7710],\n",
       "          [ 0.8925,  1.3485,  2.4901,  1.4275],\n",
       "          [ 0.5490,  0.8988,  2.6590,  1.1024],\n",
       "          [ 0.9354,  1.1024,  1.6216,  1.2698],\n",
       "          [ 4.0625,  1.4518,  0.7975,  1.3973],\n",
       "          [ 1.9768,  1.0256,  1.0283,  1.0103]]], grad_fn=<ExpandBackward>),\n",
       " 'topic_b': tensor([[[ 0.8167,  2.0569,  3.2580,  1.5621],\n",
       "          [ 3.4071,  1.6474,  1.3302,  1.3288],\n",
       "          [ 1.7870,  1.1241,  0.9602,  1.2777],\n",
       "          [ 1.6471,  1.2635,  1.3588,  1.6981],\n",
       "          [ 1.0254,  1.9123,  1.5009,  1.6490],\n",
       "          [ 1.0357,  1.8751,  1.2232,  1.1009],\n",
       "          [ 1.3071,  2.5160,  1.4286,  3.8786],\n",
       "          [ 1.3270,  1.9960,  1.4103,  1.1569],\n",
       "          [ 0.9939,  1.5472,  3.1092,  0.9845],\n",
       "          [ 1.0341,  1.9664,  0.8340,  0.6040],\n",
       "          [ 2.1674,  1.8027,  1.0863,  1.5952],\n",
       "          [ 5.6386,  3.8259,  1.7880,  2.5008],\n",
       "          [ 2.3465,  1.6951,  1.5557,  1.0774],\n",
       "          [ 1.0220,  1.6689,  2.3375,  0.9806],\n",
       "          [ 1.1843,  1.3523,  2.7415,  1.7680]],\n",
       " \n",
       "         [[ 1.7198,  2.1231,  3.9332,  1.6558],\n",
       "          [ 1.9257,  2.0813,  1.9526,  1.7792],\n",
       "          [ 2.4968,  1.5745,  0.9662,  2.0115],\n",
       "          [ 3.8823,  1.9491,  4.5847,  1.9385],\n",
       "          [ 2.2786,  1.0976,  2.0683,  2.1034],\n",
       "          [ 2.8060,  5.7383,  1.9839,  3.4281],\n",
       "          [ 2.5823,  3.1084,  2.2912,  2.6172],\n",
       "          [ 2.7562,  2.4025,  2.0699,  2.2341],\n",
       "          [ 2.6754,  3.2051,  2.1207,  1.6551],\n",
       "          [ 2.4453,  3.1843,  1.5408,  2.0017],\n",
       "          [ 7.1933,  9.3228,  1.3232,  3.1005],\n",
       "          [ 7.2684,  9.4123,  1.8075,  2.6898],\n",
       "          [ 6.4140,  3.0020,  1.8329,  3.1924],\n",
       "          [ 1.4576,  2.8722,  2.2895,  2.9015],\n",
       "          [ 1.6073,  3.8519,  4.2574,  5.5676]],\n",
       " \n",
       "         [[ 1.5003,  2.0310,  5.4512,  1.2665],\n",
       "          [ 4.8560,  5.9747,  1.4300,  1.1801],\n",
       "          [ 3.9117,  1.3536,  1.5428,  2.9060],\n",
       "          [ 5.0171,  1.0618,  7.6613,  7.0159],\n",
       "          [ 1.1450,  5.6632,  2.9130,  1.3764],\n",
       "          [ 2.2636,  4.1046,  1.1903,  1.0625],\n",
       "          [ 1.4798,  3.4499,  3.0275,  2.6456],\n",
       "          [ 2.9826,  4.5164,  1.5006,  1.3662],\n",
       "          [ 1.0535,  1.3348,  2.7526,  1.4550],\n",
       "          [ 2.1231,  4.1379,  1.1359,  0.8319],\n",
       "          [ 4.3232, 11.6050,  1.5429,  3.1928],\n",
       "          [ 3.9967, 12.7383,  1.8359,  2.1310],\n",
       "          [ 5.4279,  5.8952,  2.0010,  1.7265],\n",
       "          [ 1.1658,  8.6804,  6.4658,  3.4234],\n",
       "          [ 1.0414,  5.7035,  7.3410,  5.5101]]], grad_fn=<ExpandBackward>),\n",
       " 'participant_topics': tensor([[0.8981, 0.0530, 0.0489],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.9078, 0.0459, 0.0464],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.3198, 0.0727, 0.6075],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.7981, 0.0613, 0.1406],\n",
       "         [0.9113, 0.0441, 0.0447],\n",
       "         [0.9114, 0.0441, 0.0445],\n",
       "         [0.0452, 0.0420, 0.9128],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0445, 0.9103, 0.0452],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0447, 0.9093, 0.0460],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.9095, 0.0446, 0.0459],\n",
       "         [0.0643, 0.1504, 0.7853],\n",
       "         [0.0590, 0.8383, 0.1027],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.9019, 0.0502, 0.0479],\n",
       "         [0.0441, 0.0440, 0.9119],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0442, 0.0440, 0.9118],\n",
       "         [0.0442, 0.0441, 0.9117],\n",
       "         [0.7414, 0.1642, 0.0944],\n",
       "         [0.9098, 0.0444, 0.0458],\n",
       "         [0.9098, 0.0444, 0.0458],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0446, 0.9095, 0.0459],\n",
       "         [0.0442, 0.0440, 0.9118],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.7848, 0.1432, 0.0720],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.2987, 0.0752, 0.6261],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.9096, 0.0445, 0.0459],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.1471, 0.0626, 0.7903],\n",
       "         [0.0750, 0.2758, 0.6492],\n",
       "         [0.7312, 0.1883, 0.0805],\n",
       "         [0.9098, 0.0444, 0.0458],\n",
       "         [0.9098, 0.0444, 0.0458],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.9098, 0.0444, 0.0458],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0418, 0.0435, 0.9147],\n",
       "         [0.9098, 0.0444, 0.0458],\n",
       "         [0.9099, 0.0444, 0.0458],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0611, 0.1309, 0.8079],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.7882, 0.1396, 0.0722],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.9037, 0.0453, 0.0510],\n",
       "         [0.0440, 0.0440, 0.9121],\n",
       "         [0.9098, 0.0444, 0.0458],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.9098, 0.0444, 0.0458],\n",
       "         [0.9004, 0.0453, 0.0543],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.9098, 0.0444, 0.0458],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.6827, 0.2317, 0.0856],\n",
       "         [0.9098, 0.0444, 0.0458],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0447, 0.9093, 0.0460],\n",
       "         [0.9098, 0.0444, 0.0458],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.5595, 0.0811, 0.3594],\n",
       "         [0.0767, 0.7201, 0.2032],\n",
       "         [0.9098, 0.0444, 0.0458],\n",
       "         [0.0447, 0.9093, 0.0460],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0585, 0.0477, 0.8938],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.5061, 0.0801, 0.4138],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0447, 0.9093, 0.0460],\n",
       "         [0.0442, 0.0440, 0.9117],\n",
       "         [0.0447, 0.9093, 0.0460],\n",
       "         [0.9098, 0.0444, 0.0458],\n",
       "         [0.1729, 0.7479, 0.0792]], grad_fn=<ExpandBackward>)}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recording output from group model fitting for later use\n",
    "seed_dim = seed\n",
    "map_dim = global_guide(data)\n",
    "guide_dim = global_guide\n",
    "\n",
    "# store a copy of MAP without participant topics for new inference purposes\n",
    "map_dim_nopt = map_dim.copy()\n",
    "pt = map_dim_nopt.pop('participant_topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scarse obs model and guide\n",
    "@config_enumerate\n",
    "def model_multi_obs_dim(obsmat):\n",
    "    # some parameters can be directly derived from the data passed\n",
    "    # K = 2\n",
    "#     nparticipants = data.shape[0]\n",
    "#     nfeatures = data.shape[1] # number of rows in each person's matrix\n",
    "#     ncol = data.shape[2]\n",
    "    num_topics = K\n",
    "    nparticipants = data.shape[0]\n",
    "    nfeatures = data.shape[1] # number of rows in each person's matrix\n",
    "    ncol = data.shape[2]\n",
    "\n",
    "    if dtype == 'norm':\n",
    "        pass\n",
    "    elif dtype == 'raw':\n",
    "            \n",
    "        with pyro.plate('topic', num_topics):\n",
    "            # sample a weight and value for each topic\n",
    "            topic_weights = pyro.sample(\"topic_weights\", dist.Gamma(1. / num_topics, 1.))\n",
    "            topic_a = pyro.sample(\"topic_a\", dist.Gamma(2 * torch.ones(nfeatures,ncol),\n",
    "                                                             1/3 * torch.ones(nfeatures,ncol)).to_event(2))\n",
    "            topic_b = pyro.sample(\"topic_b\", dist.Gamma(2 * torch.ones(nfeatures,ncol),\n",
    "                                                       1/3 * torch.ones(nfeatures,ncol)).to_event(2))\n",
    "\n",
    "        # sample each participant's idiosyncratic topic mixture\n",
    "        participant_topics = pyro.sample(\"new_participant_topic\", dist.Dirichlet(topic_weights))\n",
    "        transition_topics = pyro.sample(\"new_transition_topic\", dist.Categorical(participant_topics),\n",
    "                                        infer={\"enumerate\": \"parallel\"})\n",
    "        out = dist.Beta(topic_a[transition_topics], topic_b[transition_topics]).to_event(2)\n",
    "        for r in np.arange(obsmat.shape[0]):\n",
    "            rowind = obsmat[r,1].type(torch.long)\n",
    "            colind = obsmat[r,2].type(torch.long)\n",
    "            d = dist.Beta(topic_a[transition_topics,rowind,colind],topic_b[transition_topics,rowind,colind])\n",
    "            pyro.sample('obs_{}'.format(r), d, obs = obsmat[r,0])\n",
    "            \n",
    "def new_guide(obsmat):\n",
    "    # Global variables.\n",
    "    with poutine.block(hide_types=[\"param\"]):  # Keep our learned values of global parameters.\n",
    "        map_dim_nopt\n",
    "        \n",
    "    participant_topics = pyro.sample(\"new_participant_topic\", dist.Dirichlet(map_dim_nopt['topic_weights']))\n",
    "    p_t_probs = pyro.param('p_t_probs', participant_topics)\n",
    "    transition_topics = pyro.sample(\"new_transition_topic\", dist.Categorical(p_t_probs),\n",
    "                                        infer={\"enumerate\": \"parallel\"})\n",
    "\n",
    "# new_guide = AutoDelta(poutine.block(model_multi_obs_dim, expose = ['new_participant_topic']))\n",
    "    \n",
    "def initialize_multi_obs_dim(seed, model, guide, data):\n",
    "    global svi\n",
    "    pyro.set_rng_seed(seed)\n",
    "    if 'p_t_probs' in pyro.get_param_store().keys():\n",
    "                    pyro.get_param_store().__delitem__('p_t_probs')\n",
    "    svi = SVI(model, guide, optim, loss = elbo)\n",
    "    return svi.loss(model, guide, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,0)\n",
      "(0,1)\n",
      "(0,2)\n",
      "(0,3)\n",
      "(1,0)\n",
      "(1,1)\n",
      "(1,2)\n",
      "(1,3)\n",
      "(2,0)\n",
      "(2,1)\n",
      "(2,2)\n",
      "(2,3)\n",
      "(3,0)\n",
      "(3,1)\n",
      "(3,2)\n",
      "(3,3)\n",
      "(4,0)\n",
      "(4,1)\n",
      "(4,2)\n",
      "(4,3)\n",
      "(5,0)\n",
      "(5,1)\n",
      "(5,2)\n",
      "(5,3)\n",
      "(6,0)\n",
      "(6,1)\n",
      "(6,2)\n",
      "(6,3)\n",
      "(7,0)\n",
      "(7,1)\n",
      "(7,2)\n",
      "(7,3)\n",
      "(8,0)\n",
      "(8,1)\n",
      "(8,2)\n",
      "(8,3)\n",
      "(9,0)\n",
      "(9,1)\n",
      "(9,2)\n",
      "(9,3)\n",
      "(10,0)\n",
      "(10,1)\n",
      "(10,2)\n",
      "(10,3)\n",
      "(11,0)\n",
      "(11,1)\n",
      "(11,2)\n",
      "(11,3)\n",
      "(12,0)\n",
      "(12,1)\n",
      "(12,2)\n",
      "(12,3)\n",
      "(13,0)\n",
      "(13,1)\n",
      "(13,2)\n",
      "(13,3)\n",
      "(14,0)\n",
      "(14,1)\n",
      "(14,2)\n",
      "(14,3)\n"
     ]
    }
   ],
   "source": [
    "nsteps = np.arange(.1,1,.1).shape[0]\n",
    "stor_dim_seed = torch.empty(size = [data.shape[1],data.shape[2],nsteps])\n",
    "stor_dim_init_loss = torch.empty(size = [data.shape[1],data.shape[2],nsteps])\n",
    "stor_dim_final_loss = torch.empty(size = [data.shape[1],data.shape[2],nsteps])\n",
    "stor_dim_prb = torch.empty(size = [data.shape[1],data.shape[2],nsteps,K])\n",
    "# iterate through all features, each with value .1-.9\n",
    "for row in np.arange(data.shape[1]):\n",
    "    for col in np.arange(data.shape[2]):\n",
    "#         if row == col:\n",
    "#             pass\n",
    "#         else:\n",
    "        step_count = 0\n",
    "        print('({},{})'.format(row,col))\n",
    "        for step in np.arange(.1,1,.1):\n",
    "            newdata = torch.tensor([step, row, col]).unsqueeze(0)\n",
    "            if 'p_t_probs' in pyro.get_param_store().keys():\n",
    "                pyro.get_param_store().__delitem__('p_t_probs')\n",
    "\n",
    "            loss, seed = min((initialize_multi_obs_dim(seed,model_multi_obs_dim,new_guide,newdata), seed) for seed in range(100))\n",
    "            initialize_multi_obs_dim(seed,model_multi_obs_dim,new_guide,newdata)\n",
    "            stor_dim_seed[row, col, step_count] = seed\n",
    "            stor_dim_init_loss[row,col,step_count] = loss\n",
    "            for i in range(1000):\n",
    "                loss = svi.step(newdata)\n",
    "            stor_dim_final_loss[row,col,step_count] = loss\n",
    "            stor_dim_prb[row,col,step_count,:] = pyro.get_param_store()['p_t_probs']\n",
    "            step_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fa30739c88>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot((stor_dim_final_loss - stor_dim_init_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('tomtom_scarce_param.pkl','wb') as f:\n",
    "#     pickle.dump([stor_grp, stor_grp_prb,\n",
    "#                 stor_dim_seed, stor_dim_init_loss, stor_dim_final_loss, stor_dim_prb],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "839.7295532226562\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "can't optimize a non-leaf Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-170-88a4dcdb6d06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mpyro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_param_store\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'p_t_probs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pyro\\infer\\svi.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# actually perform gradient steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;31m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# zero gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pyro\\optim\\optim.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim_objs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[1;31m# create a single optim object for that param\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim_objs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_optim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m                 \u001b[1;31m# create a gradient clipping function if specified\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_clip\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_grad_clip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pyro\\optim\\optim.py\u001b[0m in \u001b[0;36m_get_optim\u001b[1;34m(self, param)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_optim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpt_optim_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_optim_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;31m# helper to fetch the optim args if callable (only used internally)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad)\u001b[0m\n\u001b[0;32m     40\u001b[0m         defaults = dict(lr=lr, betas=betas, eps=eps,\n\u001b[0;32m     41\u001b[0m                         weight_decay=weight_decay, amsgrad=amsgrad)\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_group\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36madd_param_group\u001b[1;34m(self, param_group)\u001b[0m\n\u001b[0;32m    200\u001b[0m                                 \"but one of the params is \" + torch.typename(param))\n\u001b[0;32m    201\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"can't optimize a non-leaf Tensor\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: can't optimize a non-leaf Tensor"
     ]
    }
   ],
   "source": [
    "newdata = torch.tensor([[.9,1,1],\n",
    "                       [.9,2,2],\n",
    "                       [.1,3,3]])\n",
    "if 'p_t_probs' in pyro.get_param_store().keys():\n",
    "    pyro.get_param_store().__delitem__('p_t_probs')\n",
    "\n",
    "loss, seed = min((initialize_multi_obs_dim(seed,model_multi_obs_dim,new_guide,newdata), seed) for seed in range(100))\n",
    "initialize_multi_obs_dim(seed,model_multi_obs_dim,new_guide,newdata)\n",
    "print(loss)\n",
    "for i in range(1000):\n",
    "    loss = svi.step(newdata)\n",
    "print(loss)\n",
    "pyro.get_param_store()['p_t_probs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AutoDelta.topic_weights', 'AutoDelta.topic_a', 'AutoDelta.topic_b', 'AutoDelta.participant_topics', 'AutoDelta.new_participant_topic', 'topic_a', 'topic_b', 'topic_weights'])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyro.get_param_store().keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5256, 0.4224, 0.7553], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyro.get_param_store().setdefault('topic_a',pyro.get_param_store()['AutoDelta.topic_a'])\n",
    "pyro.get_param_store().setdefault('topic_b',pyro.get_param_store()['AutoDelta.topic_b'])\n",
    "pyro.get_param_store().setdefault('topic_weights',pyro.get_param_store()['AutoDelta.topic_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3364, 0.3311, 0.3325], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyro.get_param_store()['AutoDelta.new_participant_topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@config_enumerate\n",
    "def model(data):\n",
    "    # Global variables.\n",
    "    weights = pyro.sample('weights', dist.Dirichlet(0.5 * torch.ones(K)))\n",
    "    scale = pyro.sample('scale', dist.LogNormal(0., 2.))\n",
    "    with pyro.plate('components', K):\n",
    "        locs = pyro.sample('locs', dist.Normal(0., 10.))\n",
    "\n",
    "    with pyro.plate('data', len(data)):\n",
    "        # Local variables.\n",
    "        assignment = pyro.sample('assignment', dist.Categorical(weights))\n",
    "        pyro.sample('obs', dist.Normal(locs[assignment], scale), obs=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@config_enumerate\n",
    "def full_guide(data):\n",
    "    # Global variables.\n",
    "    with poutine.block(hide_types=[\"param\"]):  # Keep our learned values of global parameters.\n",
    "        global_guide(data)\n",
    "\n",
    "    # Local variables.\n",
    "    with pyro.plate('data', len(data)):\n",
    "        assignment_probs = pyro.param('assignment_probs', torch.ones(len(data), K) / K,\n",
    "                                      constraint=constraints.unit_interval)\n",
    "        pyro.sample('assignment', dist.Categorical(assignment_probs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
