{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data preparation and cleaning\n",
    "# importing required packages\n",
    "import pyreadr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of self-rating dataframe:  (94, 75)\n",
      "shape of target-rating dataframe:  (94, 75)\n",
      "shape of group-rating dataframe:  (94, 75)\n"
     ]
    }
   ],
   "source": [
    "# import data and convert to python objects\n",
    "# load Rdata object\n",
    "rdata = pyreadr.read_r('det_dfs.Rdata')\n",
    "# pull out separate dataframes, one with choice text, the other with numeric responses\n",
    "df = rdata['df']\n",
    "dfn = rdata['dfn']\n",
    "# df.head()\n",
    "\n",
    "\n",
    "# read in state labels\n",
    "states = pd.read_csv('tomtom_data/states.csv')\n",
    "states['statepair'] = states['state1'] + '_' + states['state2']# construct state pair strings\n",
    "# states.head()\n",
    "\n",
    "# extract all the self ratings\n",
    "ind_selfq1 = df.columns.get_loc('X1_Q12_1') # location of the first question\n",
    "trans_self = df.iloc[:,list(range(ind_selfq1,(ind_selfq1+75)))]\n",
    "print('shape of self-rating dataframe: ',trans_self.shape)\n",
    "trans_self.columns = states['statepair'].tolist() # renaming transitioin columns with the corresponding transition pairs\n",
    "\n",
    "# extract all the specific target ratings\n",
    "ind_targq1 = df.columns.get_loc('X1_Q9_1') # location of the first question\n",
    "trans_targ = df.iloc[:,list(range(ind_targq1,(ind_targq1+75)))]\n",
    "print('shape of target-rating dataframe: ', trans_targ.shape)\n",
    "trans_targ.columns = states['statepair'].tolist() # renaming transitioin columns with the corresponding transition pairs\n",
    "\n",
    "# extract all the group level ratings\n",
    "ind_avgq1 = df.columns.get_loc('X1_Q11_1') # location of the first question\n",
    "trans_avg = df.iloc[:,list(range(ind_avgq1,(ind_avgq1+75)))]\n",
    "print('shape of group-rating dataframe: ', trans_avg.shape)\n",
    "trans_avg.columns = states['statepair'].tolist() # renaming transitioin columns with the corresponding transition pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reusable code for pre processing each of the three sets of ratings into pyro compatible format\n",
    "\n",
    "# altering edge values to avoid rounding errors while sampling\n",
    "def de_edge_raw(t):\n",
    "    t[t == 0] = .0001\n",
    "    t[t == 1] = .9999\n",
    "    return t\n",
    "\n",
    "def de_edge_norm(t):\n",
    "    ## in the normed data there's no 1s\n",
    "    # change 0 to .0001 and decrement the max value of the same row by .0001 \n",
    "    # in order to make sure the row still sums to 1\n",
    "    ind_zero = np.where(t == 0)\n",
    "    t[ind_zero] += .0001\n",
    "    ind_max = np.argmax(t,axis = 2)\n",
    "    for i in np.arange(ind_zero[0].shape[0]):\n",
    "        temp_max = ind_max[ind_zero[0][i],ind_zero[1][i]]\n",
    "        t[ind_zero[0][i],ind_zero[1][i],temp_max] -= .0001\n",
    "    return t\n",
    "\n",
    "def data_transform(trans):\n",
    "    # set the constant for converting probability to frequency\n",
    "    freq_constant = 10000\n",
    "    # indexing autotransition columns\n",
    "    colnames = trans.columns.tolist()\n",
    "    cnsplit = [p.split('_') for p in colnames]\n",
    "    idx_autotransition = [p[0] == p[1] for p in cnsplit] # list of boolean, True = is autotransition\n",
    "    \n",
    "    # 1. normalizing with autotransitions included, one df for probability, one converted to frequency\n",
    "    # initialize 2 dataframes\n",
    "    t_norm_all = pd.DataFrame(columns=trans.columns, index = trans.index)\n",
    "    t_norm_all_f =  pd.DataFrame(columns=trans.columns, index = trans.index)\n",
    "    \n",
    "    # normalize by row-sum every five columns, since the columns are already arranged by from-state in 5\n",
    "    for i in range(0,trans.shape[1],5):\n",
    "        dftemp = trans.iloc[:,i:(i+5)]\n",
    "        dftemp_rowsum = dftemp.sum(axis = 1)\n",
    "        normed_cols = dftemp/dftemp_rowsum[:,np.newaxis]\n",
    "        t_norm_all.iloc[:,i:(i+5)] = normed_cols\n",
    "        t_norm_all_f.iloc[:,i:(i+5)] = (normed_cols * freq_constant).round()\n",
    "        \n",
    "    # 2. two additional dataframes: normed with auto transition but don't contain them\n",
    "    t_norm_all_noauto = t_norm_all.loc[:,[not t for t in idx_autotransition]]\n",
    "    t_norm_all_noauto_f = t_norm_all_f.loc[:,[not t for t in idx_autotransition]]\n",
    "\n",
    "    # 3. finally, normalizing without autotransitions, and also convert to frequency\n",
    "    trans_noauto = trans.loc[:,[not t for t in idx_autotransition]]\n",
    "    t_norm_noauto = pd.DataFrame(columns=trans_noauto.columns, index = trans_noauto.index)\n",
    "    t_norm_noauto_f = pd.DataFrame(columns=trans_noauto.columns, index = trans_noauto.index)\n",
    "\n",
    "    # normalize by row-sum every FOUR columns, grouped by from-state in 4 without autotransition\n",
    "    for i in range(0,trans_noauto.shape[1],4):\n",
    "        dftemp = trans_noauto.iloc[:,i:(i+4)]\n",
    "        dftemp_rowsum = dftemp.sum(axis = 1)\n",
    "        normed_cols = dftemp/dftemp_rowsum[:,np.newaxis]\n",
    "        t_norm_noauto.iloc[:,i:(i+5)] = normed_cols\n",
    "        t_norm_noauto_f.iloc[:,i:(i+5)] = (normed_cols * freq_constant).round()\n",
    "        \n",
    "    t_norm_all_3d = torch.tensor(np.stack([np.array(t_norm_all.iloc[i]).reshape(15,5) \n",
    "                                        for i in np.arange(t_norm_all.shape[0])]).astype('float32'))\n",
    "    t_norm_noauto_3d = torch.tensor(np.stack([np.array(t_norm_noauto.iloc[i]).reshape(15,4) \n",
    "                                            for i in np.arange(t_norm_noauto.shape[0])]).astype('float32'))\n",
    "    t_raw_all_3d = torch.tensor(np.stack([np.array(trans.iloc[i]).reshape(15,5) \n",
    "                                            for i in np.arange(trans.shape[0])]).astype('float32'))\n",
    "    t_raw_noauto_3d = torch.tensor(np.stack([np.array(trans_noauto.iloc[i]).reshape(15,4) \n",
    "                                            for i in np.arange(trans_noauto.shape[0])]).astype('float32'))\n",
    "    \n",
    "    return de_edge_norm(t_norm_all_3d), de_edge_norm(t_norm_noauto_3d), de_edge_raw(t_raw_all_3d/100), de_edge_raw(t_raw_noauto_3d/100)\n",
    "#     return t_norm_all_3d, t_norm_noauto_3d, de_edge(t_raw_all_3d/100), de_edge(t_raw_noauto_3d/100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tself_norm_all_3d, tself_norm_noauto_3d, tself_raw_all_3d, tself_raw_noauto_3d = data_transform(trans_self)\n",
    "ttarg_norm_all_3d, ttarg_norm_noauto_3d, ttarg_raw_all_3d, ttarg_raw_noauto_3d = data_transform(trans_targ)\n",
    "tavg_norm_all_3d, tavg_norm_noauto_3d, tavg_raw_all_3d, tavg_raw_noauto_3d = data_transform(trans_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to file for easy import\n",
    "with open('tomtom_data_preprocessed.pkl', 'wb') as f:  \n",
    "    pickle.dump([tself_norm_all_3d, tself_norm_noauto_3d, tself_raw_all_3d, tself_raw_noauto_3d,\n",
    "                 ttarg_norm_all_3d, ttarg_norm_noauto_3d, ttarg_raw_all_3d, ttarg_raw_noauto_3d,\n",
    "                 tavg_norm_all_3d, tavg_norm_noauto_3d, tavg_raw_all_3d, tavg_raw_noauto_3d], f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
